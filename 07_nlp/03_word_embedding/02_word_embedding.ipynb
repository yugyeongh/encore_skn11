{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Word Enbedding**은 단어를 고정된 차원의 벡터로 변환하는 기술로, 단어 간의 의미적 유사성을 반영하도록 학습된 벡터를 말한다.\n",
    "- 이 기술은 자연어 처리에서 문장을 처리하고 이해하는 데 활용된다.\n",
    "- 숫자로 표현된 단어 목록을 통해 감정을 추출하는 것도 가능하다.\n",
    "- 연관성 있는 단어들을 군집화하여 다차원 공간에 벡터로 나타낼 수 있으며, 이는 단어나 문장을 벡터 공간에 매핑하는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Matrix 예시**\n",
    "\n",
    "*아래 표의 벡터 값들은 모두 기계 학습을 통해 학습된 결과이다.*  \n",
    "\n",
    "| Dimension | Man (5391) | Woman (9853) | King (4914) | Queen (7157) | Apple (456) | Orange (6257) |\n",
    "|-----------|------------|--------------|-------------|--------------|-------------|---------------|\n",
    "| 성별      | -1         | 1            | -0.95       | 0.97         | 0.00        | 0.01          |\n",
    "| 귀족      | 0.01       | 0.02         | 0.93        | 0.95         | -0.01       | 0.00          |\n",
    "| 나이      | 0.03       | 0.02         | 0.7         | 0.69         | 0.03        | -0.02         |\n",
    "| 음식      | 0.04       | 0.01         | 0.02        | 0.01         | 0.95        | 0.97          |\n",
    "\n",
    "<br>\n",
    "\n",
    "*아래는 전치된 표이다.*\n",
    "\n",
    "| Word          | 성별   | 귀족   | 나이   | 음식   |\n",
    "|---------------|--------|--------|--------|--------|\n",
    "| Man (5391)    | -1.00  | 0.01   | 0.03   | 0.04   |\n",
    "| Woman (9853)  | 1.00   | 0.02   | 0.02   | 0.01   |\n",
    "| King (4914)   | -0.95  | 0.93   | 0.70   | 0.02   |\n",
    "| Queen (7157)  | 0.97   | 0.95   | 0.69   | 0.01   |\n",
    "| Apple (456)   | 0.00   | -0.01  | 0.03   | 0.95   |\n",
    "| Orange (6257) | 0.01   | 0.00   | -0.02  | 0.97   |\n",
    "\n",
    "- **의미적 유사성 반영**  \n",
    "  - 단어를 고정된 크기의 실수 벡터로 표현하며, 비슷한 의미를 가진 단어는 벡터 공간에서 가깝게 위치한다.  \n",
    "  - 예를 들어, \"king\"과 \"queen\"은 비슷한 맥락에서 자주 사용되므로 벡터 공간에서 가까운 위치에 배치된다.  \n",
    "\n",
    "- **밀집 벡터(Dense Vector)**  \n",
    "  - BoW, DTM, TF-IDF와 달리 Word Embedding은 저차원 밀집 벡터로 변환되며, 차원이 낮으면서도 의미적으로 풍부한 정보를 담는다.  \n",
    "  - 벡터 차원은 보통 100 또는 300 정도로 제한된다.  \n",
    "\n",
    "- **문맥 정보 반영**  \n",
    "  - Word Embedding은 단어 주변의 단어들을 학습해 단어의 의미를 추론한다.  \n",
    "  - 예를 들어, \"bank\"라는 단어가 \"river\"와 함께 나오면 \"강둑\"을, \"money\"와 함께 나오면 \"은행\"을 의미한다고 학습한다.  \n",
    "\n",
    "- **학습 기반 벡터**  \n",
    "  - Word Embedding은 대규모 텍스트 데이터에서 단어 간 연관성을 학습해 벡터를 생성한다.  \n",
    "  - 반면, BoW나 TF-IDF는 단순한 규칙 기반 벡터화 방법이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 희소 표현(Sparse Representation) | 분산 표현(Distributed Representation)\n",
    "- 원-핫 인코딩으로 얻은 원-핫 벡터는 단어의 인덱스 값만 1이고 나머지는 모두 0으로 표현된다.\n",
    "- 이렇게 대부분의 값이 0인 벡터나 행렬을 사용하는 표현 방식을 희소 표현(sparse representation)이라고 한다.  \n",
    "- 희소 표현은 단어 벡터 간 유의미한 유사성을 표현할 수 없다는 단점이 있다.\n",
    "- 이를 해결하기 위해 단어의 의미를 다차원 공간에 벡터화하는 분산 표현(distributed representation)을 사용한다.\n",
    "- 분산 표현으로 단어 간 의미적 유사성을 벡터화하는 작업을 워드 임베딩(embedding)이라고 하며, 이렇게 변환된 벡터를 임베딩 벡터(embedding vector)라고 한다.  \n",
    "- **원-핫 인코딩 → 희소 표현**  \n",
    "- **워드 임베딩 → 분산 표현**  \n",
    "\n",
    "**분산 표현(Distributed Representation)**\n",
    "- 분산 표현은 분포 가설(distributional hypothesis)에 기반한 방법이다.\n",
    "- 이 가설은 \"비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 가진다\"는 내용을 전제로 한다.\n",
    "- 예를 들어, '강아지'라는 단어는 '귀엽다', '예쁘다', '애교' 등의 단어와 함께 자주 등장하며, 이를 벡터화하면 해당 단어들은 유사한 벡터값을 갖게 된다.\n",
    "- 분산 표현은 단어의 의미를 여러 차원에 걸쳐 분산하여 표현한다.  \n",
    "- 이 방식은 원-핫 벡터처럼 단어 집합 크기만큼의 차원이 필요하지 않으며, 상대적으로 저차원으로 줄어든다.\n",
    "- 예를 들어, 단어 집합 크기가 10,000이고 '강아지'의 인덱스가 4라면, 원-핫 벡터는 다음과 같다:\n",
    "  \n",
    "- **강아지 = [0 0 0 0 1 0 0 ... 0]** (뒤에 9,995개의 0 포함)  \n",
    "- 그러나 Word2Vec으로 임베딩된 벡터는 단어 집합 크기와 무관하며, 설정된 차원의 수만큼 실수값을 가진 벡터가 된다:  \n",
    "- **강아지 = [0.2 0.3 0.5 0.7 0.2 ... 0.2]**  \n",
    "\n",
    "**요약하면,**\n",
    "- 희소 표현은 고차원에서 각 차원이 분리된 방식으로 단어를 표현하지만, 분산 표현은 저차원에서 단어의 의미를 여러 차원에 분산시켜 표현한다.\n",
    "- 이를 통해 단어 벡터 간 유의미한 유사도를 계산할 수 있으며, 대표적인 학습 방법으로 Word2Vec이 사용된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Vector 시각화 wevi\n",
    "https://ronxin.github.io/wevi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "- 2013년 구글에서 개발한 Word Embedding 방법\n",
    "- 최초의 neural embedding model\n",
    "- 매우 큰 corpus에서 자동 학습\n",
    "    - 비지도 지도 학습 (자기 지도학습)이라 할 수 있음\n",
    "    - 많은 데이터를 기반으로 label 값 유추하고 이를 지도학습에 사용\n",
    "        - label 값을 유추한다 == 벡터값을 유추한다\n",
    "- ex) \n",
    "    - **이사금**께 충성을 맹세하였다.\n",
    "    - **왕**께 충성을 맹세하였다.\n",
    "\n",
    "**WordVec 훈련방식에 따른 구분**\n",
    "1. CBOW : 주변 단어로 중심 단어를 예측\n",
    "2. Skip-gram : 중심 단어로 주변 단어를 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CBOW (Continuous Bag of Words)  \n",
    "- CBOW는 원-핫 벡터를 사용하지만, 이는 단순히 위치를 가리킬 뿐 vocabulary를 직접적으로 참조하지 않는다.  \n",
    "\n",
    "**예시:**  \n",
    "\n",
    "> The fat cat sat on the mat  \n",
    "\n",
    "주어진 문장에서 'sat'이라는 단어를 예측하는 것이 CBOW의 주요 작업이다.  \n",
    "- **중심 단어(center word):** 예측하려는 단어 ('sat')  \n",
    "- **주변 단어(context word):** 예측에 사용되는 단어들  \n",
    "\n",
    "중심 단어를 예측하기 위해 앞뒤 몇 개의 단어를 참고할지 결정하는 범위를 **윈도우(window)**라고 한다.  \n",
    "예를 들어, 윈도우 크기가 2이고 중심 단어가 'sat'라면, 앞의 두 단어(fat, cat)와 뒤의 두 단어(on, the)를 입력으로 사용한다.  \n",
    "윈도우 크기가 n일 경우, 참고하는 주변 단어의 개수는 총 2n이다. 윈도우를 옆으로 이동하며 학습 데이터를 생성하는 방법을 **슬라이딩 윈도우(sliding window)**라고 한다.  \n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG)\n",
    "\n",
    "\n",
    "**훈련 과정**\n",
    "\n",
    "CBOW는 embedding 벡터를 학습하기 위한 구조를 갖는다. 초기에는 가중치가 임의의 값으로 설정되며, 역전파를 통해 최적화된다.  \n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/word2vec_renew_1.PNG)\n",
    "\n",
    "Word2Vec은 은닉층이 하나뿐인 얕은 신경망(shallow neural network) 구조를 사용한다.  \n",
    "학습 대상이 되는 주요 가중치는 두 가지이다:  \n",
    "\n",
    "1. **투사층(projection layer):**  \n",
    "   - 활성화 함수가 없으며 룩업 테이블 연산을 담당한다.  \n",
    "   - 입력층과 투사층 사이의 가중치 W는 V × M 행렬로 표현되며, 여기서 **V는 단어 집합의 크기, M은 벡터의 차원**이다.  \n",
    "   - W 행렬의 각 행은 학습 후 단어의 M차원 임베딩 벡터로 간주된다.  \n",
    "   - 예를 들어, 벡터 차원을 5로 설정하면 각 단어의 임베딩 벡터는 5차원이 된다.  \n",
    "\n",
    "2. **출력층:**  \n",
    "   - 투사층과 출력층 사이의 가중치 W'는 M × V 행렬로 표현된다.  \n",
    "   - 이 두 행렬(W와 W')은 서로 독립적이며, 학습 전에는 랜덤 값으로 초기화된다.  \n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/word2vec_renew_3.PNG)\n",
    "\n",
    "\n",
    "**예측 과정**\n",
    "1. CBOW는 계산된 룩업 테이블의 평균을 구한 뒤, 출력층의 가중치 W'와 내적한다.  \n",
    "2. 결과값은 **소프트맥스(softmax)** 활성화 함수에 입력되어, 중심 단어일 확률을 나타내는 예측값으로 변환된다.  \n",
    "3. 출력된 예측값(스코어 벡터)은 실제 타겟 원-핫 벡터와 비교되며, **크로스 엔트로피(cross-entropy)** 함수로 손실값을 계산한다.  \n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/word2vec_renew_5.PNG)\n",
    "\n",
    "손실 함수 식:  \n",
    "$\n",
    "cost(\\hat{y}, y) = -\\sum_{j=1}^{V} y_{j} \\cdot log(\\hat{y}_{j})\n",
    "$  \n",
    "\n",
    "여기서, $\\hat{y}_{j}$는 예측 확률, $y_{j}$는 실제 값이며, V는 단어 집합의 크기를 의미한다.  \n",
    "\n",
    "\n",
    "**학습 결과**  \n",
    "- 역전파를 통해 가중치 W와 W'가 학습된다. \n",
    "- 학습이 완료되면 W 행렬의 각 행을 단어의 임베딩 벡터로 사용하거나, W와 W' 모두를 이용해 임베딩 벡터를 생성할 수 있다.  \n",
    "- CBOW는 주변 단어를 기반으로 중심 단어를 예측하는 구조를 갖추고 있으며, 이를 통해 단어 간 의미적 관계를 효과적으로 학습할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip-gram\n",
    "- Skip-gram은 중심 단어에서 주변 단어를 예측한다.\n",
    "- 윈도우 크기가 2일 때, 데이터셋은 다음과 같이 구성된다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/skipgram_dataset.PNG)\n",
    "\n",
    "![](https://wikidocs.net/images/page/22660/word2vec_renew_6.PNG)\n",
    "\n",
    "- 중심 단어에 대해서 주변 단어를 예측하므로 투사층에서 벡터들의 평균을 구하는 과정은 없다.\n",
    "- 여러 논문에서 성능 비교를 진행했을 때 전반적으로 Skip-gram이 CBOW보다 성능이 좋다고 알려져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 영어 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 취득 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TF1yAHF3qRINbXWFOajFjUCxUF64QZMX\n",
      "From (redirected): https://drive.google.com/uc?id=1TF1yAHF3qRINbXWFOajFjUCxUF64QZMX&confirm=t&uuid=905fe8be-3c69-4b3c-9b44-5e142484139d\n",
      "To: c:\\encore_skn11\\07_nlp\\03_word_embedding\\ted_en.xml\n",
      "100%|██████████| 74.5M/74.5M [00:06<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ted_en.xml'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown \n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1TF1yAHF3qRINbXWFOajFjUCxUF64QZMX'\n",
    "output = 'ted_en.xml'\n",
    "\n",
    "gdown.download(url, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree      # xml 데이터를 파싱하고 인터페이스를 조작하는데 사용\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24222849\n",
      "24062319\n"
     ]
    }
   ],
   "source": [
    "# xml 데이터 처리\n",
    "f = open('ted_en.xml', 'r', encoding='utf-8')\n",
    "xml = etree.parse(f)\n",
    "\n",
    "contents = xml.xpath('//content/text()')        # content 태그 하위 텍스트\n",
    "# contents[:5]\n",
    "\n",
    "corpus = '\\n'.join(contents)    # 하나의 corpus로 만들어주기 위해 \\n에 대해 뭉쳐줌\n",
    "print(len(corpus))              # 글자 수\n",
    "\n",
    "# 정규식을 이용해  (Laughter). (Applause) 등 키워드 제거\n",
    "corpus = re.sub(r'\\([^)]*\\)', '', corpus)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식 처리 url: https://regexr.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'reasons', 'companies', 'fail', 'new'],\n",
       " ['real',\n",
       "  'real',\n",
       "  'solution',\n",
       "  'quality',\n",
       "  'growth',\n",
       "  'figuring',\n",
       "  'balance',\n",
       "  'two',\n",
       "  'activities',\n",
       "  'exploration',\n",
       "  'exploitation'],\n",
       " ['necessary', 'much', 'good', 'thing'],\n",
       " ['consider', 'facit'],\n",
       " ['actually', 'old', 'enough', 'remember']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 (토큰화/대소문자 정규화/불용어 처리)\n",
    "preprocessed_sentences = []\n",
    "sentences = sent_tokenize(corpus)\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^a-z0-9]', ' ', sentence)      # 영소문자, 숫자 외 제거\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    preprocessed_sentences.append(tokens)\n",
    "\n",
    "preprocessed_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21462, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec \n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences,       # corpus\n",
    "    vector_size=100,                        # 임베딩 벡터 차원\n",
    "    sg=0,                                   # 학습 알고리즘 선택 (0=CBOW, 1=Skip-gram)    # 0:false, cbow 알고리즘 학습 방식 선택\n",
    "    window=5,                               # 주변 단어 수 (앞뒤로 n개 고려) # 중심 단어 옆에 있는 주변 단어의 개수를 명시\n",
    "    min_count=5                             # 최소 빈도 (빈도 n개 미만은 제거)\n",
    ")\n",
    "\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>-0.791463</td>\n",
       "      <td>-0.125504</td>\n",
       "      <td>-0.902539</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>-0.195016</td>\n",
       "      <td>-0.502611</td>\n",
       "      <td>-0.226133</td>\n",
       "      <td>0.720916</td>\n",
       "      <td>-2.530587</td>\n",
       "      <td>-0.723168</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130604</td>\n",
       "      <td>1.034047</td>\n",
       "      <td>-0.671713</td>\n",
       "      <td>-0.265611</td>\n",
       "      <td>1.064838</td>\n",
       "      <td>-1.850717</td>\n",
       "      <td>-0.731692</td>\n",
       "      <td>-0.535325</td>\n",
       "      <td>0.636222</td>\n",
       "      <td>0.818261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>-1.936123</td>\n",
       "      <td>0.275479</td>\n",
       "      <td>-0.397981</td>\n",
       "      <td>0.492109</td>\n",
       "      <td>-0.657745</td>\n",
       "      <td>-1.726404</td>\n",
       "      <td>-0.432680</td>\n",
       "      <td>1.260411</td>\n",
       "      <td>-1.133667</td>\n",
       "      <td>-2.364977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808631</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>-1.566207</td>\n",
       "      <td>-0.062693</td>\n",
       "      <td>-0.432759</td>\n",
       "      <td>0.034271</td>\n",
       "      <td>-0.625112</td>\n",
       "      <td>-0.805409</td>\n",
       "      <td>-1.344495</td>\n",
       "      <td>1.057321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.501158</td>\n",
       "      <td>0.642413</td>\n",
       "      <td>-0.724876</td>\n",
       "      <td>-0.924613</td>\n",
       "      <td>-0.406479</td>\n",
       "      <td>-0.368886</td>\n",
       "      <td>0.345341</td>\n",
       "      <td>0.551563</td>\n",
       "      <td>-1.714742</td>\n",
       "      <td>1.140499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472735</td>\n",
       "      <td>0.844273</td>\n",
       "      <td>-0.526408</td>\n",
       "      <td>0.105966</td>\n",
       "      <td>-0.436837</td>\n",
       "      <td>0.568665</td>\n",
       "      <td>0.570801</td>\n",
       "      <td>-0.285344</td>\n",
       "      <td>0.703991</td>\n",
       "      <td>-0.893044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-0.781171</td>\n",
       "      <td>-0.246071</td>\n",
       "      <td>-0.185216</td>\n",
       "      <td>0.132586</td>\n",
       "      <td>0.237486</td>\n",
       "      <td>0.150584</td>\n",
       "      <td>-0.509588</td>\n",
       "      <td>-0.018378</td>\n",
       "      <td>-0.709321</td>\n",
       "      <td>-0.926525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309280</td>\n",
       "      <td>0.422332</td>\n",
       "      <td>-0.106918</td>\n",
       "      <td>-0.303081</td>\n",
       "      <td>-0.062204</td>\n",
       "      <td>0.287954</td>\n",
       "      <td>0.298779</td>\n",
       "      <td>-0.951085</td>\n",
       "      <td>0.756701</td>\n",
       "      <td>-0.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>-0.972955</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>-0.229628</td>\n",
       "      <td>-0.352750</td>\n",
       "      <td>1.452302</td>\n",
       "      <td>0.650055</td>\n",
       "      <td>-1.207264</td>\n",
       "      <td>1.023082</td>\n",
       "      <td>-0.516006</td>\n",
       "      <td>-0.322313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325520</td>\n",
       "      <td>-0.761614</td>\n",
       "      <td>0.057865</td>\n",
       "      <td>1.810420</td>\n",
       "      <td>0.107441</td>\n",
       "      <td>-0.202046</td>\n",
       "      <td>0.215803</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>-0.888326</td>\n",
       "      <td>-0.030081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>-0.081411</td>\n",
       "      <td>-0.233225</td>\n",
       "      <td>0.924462</td>\n",
       "      <td>-0.612446</td>\n",
       "      <td>0.140887</td>\n",
       "      <td>-0.858705</td>\n",
       "      <td>0.085944</td>\n",
       "      <td>-0.205714</td>\n",
       "      <td>-1.029608</td>\n",
       "      <td>-1.051871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579690</td>\n",
       "      <td>1.420662</td>\n",
       "      <td>-0.529130</td>\n",
       "      <td>0.077793</td>\n",
       "      <td>0.710808</td>\n",
       "      <td>-0.185819</td>\n",
       "      <td>-0.275865</td>\n",
       "      <td>-0.886057</td>\n",
       "      <td>-0.253077</td>\n",
       "      <td>0.012585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.423545</td>\n",
       "      <td>-0.291065</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>-1.250848</td>\n",
       "      <td>-1.036312</td>\n",
       "      <td>-0.739084</td>\n",
       "      <td>-0.118781</td>\n",
       "      <td>0.398655</td>\n",
       "      <td>-1.692369</td>\n",
       "      <td>0.464334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674388</td>\n",
       "      <td>1.041003</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>0.469586</td>\n",
       "      <td>-0.801230</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.124814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.622132</td>\n",
       "      <td>0.367256</td>\n",
       "      <td>0.594133</td>\n",
       "      <td>-0.477011</td>\n",
       "      <td>1.104367</td>\n",
       "      <td>0.264912</td>\n",
       "      <td>-0.524888</td>\n",
       "      <td>0.210952</td>\n",
       "      <td>-0.984604</td>\n",
       "      <td>-0.352938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060383</td>\n",
       "      <td>-0.884843</td>\n",
       "      <td>-0.909925</td>\n",
       "      <td>1.440473</td>\n",
       "      <td>-0.379960</td>\n",
       "      <td>1.076033</td>\n",
       "      <td>-1.244216</td>\n",
       "      <td>-0.837380</td>\n",
       "      <td>-1.167326</td>\n",
       "      <td>-0.966066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-2.441720</td>\n",
       "      <td>-0.562774</td>\n",
       "      <td>0.199173</td>\n",
       "      <td>0.238307</td>\n",
       "      <td>-0.204388</td>\n",
       "      <td>-0.327755</td>\n",
       "      <td>0.911860</td>\n",
       "      <td>1.564260</td>\n",
       "      <td>-0.194869</td>\n",
       "      <td>-0.381106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>-0.329991</td>\n",
       "      <td>-0.026275</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.326238</td>\n",
       "      <td>-0.142513</td>\n",
       "      <td>-0.294378</td>\n",
       "      <td>-1.567273</td>\n",
       "      <td>-0.151262</td>\n",
       "      <td>0.208906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>-2.343273</td>\n",
       "      <td>-1.792181</td>\n",
       "      <td>-1.302520</td>\n",
       "      <td>-0.857274</td>\n",
       "      <td>-0.016485</td>\n",
       "      <td>-1.071976</td>\n",
       "      <td>-0.557752</td>\n",
       "      <td>1.822457</td>\n",
       "      <td>-0.021536</td>\n",
       "      <td>-1.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>-0.250832</td>\n",
       "      <td>-0.426072</td>\n",
       "      <td>0.701579</td>\n",
       "      <td>0.771619</td>\n",
       "      <td>0.551090</td>\n",
       "      <td>0.177128</td>\n",
       "      <td>-0.225811</td>\n",
       "      <td>-0.933781</td>\n",
       "      <td>0.487022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "one    -0.791463 -0.125504 -0.902539  0.650804 -0.195016 -0.502611 -0.226133   \n",
       "people -1.936123  0.275479 -0.397981  0.492109 -0.657745 -1.726404 -0.432680   \n",
       "like   -0.501158  0.642413 -0.724876 -0.924613 -0.406479 -0.368886  0.345341   \n",
       "know   -0.781171 -0.246071 -0.185216  0.132586  0.237486  0.150584 -0.509588   \n",
       "going  -0.972955  0.343255 -0.229628 -0.352750  1.452302  0.650055 -1.207264   \n",
       "think  -0.081411 -0.233225  0.924462 -0.612446  0.140887 -0.858705  0.085944   \n",
       "see     0.423545 -0.291065  0.431734 -1.250848 -1.036312 -0.739084 -0.118781   \n",
       "would   0.622132  0.367256  0.594133 -0.477011  1.104367  0.264912 -0.524888   \n",
       "really -2.441720 -0.562774  0.199173  0.238307 -0.204388 -0.327755  0.911860   \n",
       "get    -2.343273 -1.792181 -1.302520 -0.857274 -0.016485 -1.071976 -0.557752   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "one     0.720916 -2.530587 -0.723168  ...  1.130604  1.034047 -0.671713   \n",
       "people  1.260411 -1.133667 -2.364977  ...  0.808631  0.322375 -1.566207   \n",
       "like    0.551563 -1.714742  1.140499  ... -0.472735  0.844273 -0.526408   \n",
       "know   -0.018378 -0.709321 -0.926525  ...  0.309280  0.422332 -0.106918   \n",
       "going   1.023082 -0.516006 -0.322313  ...  0.325520 -0.761614  0.057865   \n",
       "think  -0.205714 -1.029608 -1.051871  ...  0.579690  1.420662 -0.529130   \n",
       "see     0.398655 -1.692369  0.464334  ... -0.674388  1.041003  0.385592   \n",
       "would   0.210952 -0.984604 -0.352938  ...  1.060383 -0.884843 -0.909925   \n",
       "really  1.564260 -0.194869 -0.381106  ...  0.894602 -0.329991 -0.026275   \n",
       "get     1.822457 -0.021536 -1.658145  ... -0.424863 -0.250832 -0.426072   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "one    -0.265611  1.064838 -1.850717 -0.731692 -0.535325  0.636222  0.818261  \n",
       "people -0.062693 -0.432759  0.034271 -0.625112 -0.805409 -1.344495  1.057321  \n",
       "like    0.105966 -0.436837  0.568665  0.570801 -0.285344  0.703991 -0.893044  \n",
       "know   -0.303081 -0.062204  0.287954  0.298779 -0.951085  0.756701 -0.482900  \n",
       "going   1.810420  0.107441 -0.202046  0.215803 -0.021497 -0.888326 -0.030081  \n",
       "think   0.077793  0.710808 -0.185819 -0.275865 -0.886057 -0.253077  0.012585  \n",
       "see     0.676447  0.001916  0.131928  0.469586 -0.801230  0.615999  0.124814  \n",
       "would   1.440473 -0.379960  1.076033 -1.244216 -0.837380 -1.167326 -0.966066  \n",
       "really  0.186121  0.326238 -0.142513 -0.294378 -1.567273 -0.151262  0.208906  \n",
       "get     0.701579  0.771619  0.551090  0.177128 -0.225811 -0.933781  0.487022  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(model.wv.vectors, index=model.wv.index_to_key).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 임베딩 모델 저장\n",
    "model.wv.save_word2vec_format('ted_en_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "load_model = KeyedVectors.load_word2vec_format('ted_en_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8918129801750183),\n",
       " ('girl', 0.7996560335159302),\n",
       " ('lady', 0.7841523885726929),\n",
       " ('daughter', 0.7841269373893738),\n",
       " ('son', 0.760382890701294),\n",
       " ('boy', 0.7584336996078491),\n",
       " ('grandfather', 0.7511534094810486),\n",
       " ('father', 0.744438111782074),\n",
       " ('sister', 0.72794109582901),\n",
       " ('brother', 0.7264459133148193)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.most_similar('man')  # word2vec.wv == KeyedVectors\n",
    "# model.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7084795"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man', 'husband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.similarity('man', 'abracadabra') # 임베딩 벡터에 없는 단어로 조회 시 KeyError 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41873693, -0.31060576,  0.9205491 ,  1.6189712 , -0.98454595,\n",
       "       -0.19080062, -0.5143066 ,  1.3940036 , -0.500929  , -1.1232185 ,\n",
       "        0.18211599,  0.8279565 , -0.21572907,  0.273414  ,  1.0883671 ,\n",
       "       -0.5749561 ,  0.72270447,  0.03046436, -1.0825393 , -0.02655124,\n",
       "        0.7805755 ,  0.86324257,  0.0104557 , -0.5431433 ,  0.45892018,\n",
       "        0.25530988, -0.887295  , -0.73532397, -0.08577111,  1.238601  ,\n",
       "       -0.9526153 , -1.2033839 , -0.207517  , -1.3430954 , -0.2377062 ,\n",
       "        0.9278185 , -0.11415969, -0.4545297 ,  0.37586495, -0.14629735,\n",
       "        1.1643667 ,  0.5642611 ,  0.79735637,  0.51034147,  2.0151942 ,\n",
       "       -0.2675093 , -1.0493823 ,  0.40723312,  0.08401095, -0.52674526,\n",
       "        0.6995869 , -0.2588918 ,  0.25624406, -0.8719027 , -0.08911832,\n",
       "        0.776215  ,  0.33288407,  0.34623566, -0.16564311,  0.01750955,\n",
       "       -0.07142716, -0.64413697, -1.8633269 ,  1.3605239 , -1.0066785 ,\n",
       "        0.5455204 , -0.01215056,  0.14796275,  0.5336817 ,  1.4059262 ,\n",
       "       -0.89917177, -1.8282423 ,  0.11325808, -0.7052246 ,  0.22107765,\n",
       "        1.2132165 ,  0.3022798 ,  0.870041  ,  1.016764  , -0.5030119 ,\n",
       "       -0.7959648 ,  0.02712202, -1.119066  ,  1.3294834 , -0.5570173 ,\n",
       "       -0.06093549, -0.577442  , -0.5651625 ,  0.3288834 ,  0.3863012 ,\n",
       "       -0.2332233 , -0.7029712 ,  0.2134215 , -1.6153781 ,  0.64032334,\n",
       "        0.18149072,  0.7775019 , -0.24040484,  0.01531528, -1.3189698 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41873693, -0.31060576,  0.9205491 ,  1.6189712 , -0.98454595,\n",
       "       -0.19080062, -0.5143066 ,  1.3940036 , -0.500929  , -1.1232185 ,\n",
       "        0.18211599,  0.8279565 , -0.21572907,  0.273414  ,  1.0883671 ,\n",
       "       -0.5749561 ,  0.72270447,  0.03046436, -1.0825393 , -0.02655124,\n",
       "        0.7805755 ,  0.86324257,  0.0104557 , -0.5431433 ,  0.45892018,\n",
       "        0.25530988, -0.887295  , -0.73532397, -0.08577111,  1.238601  ,\n",
       "       -0.9526153 , -1.2033839 , -0.207517  , -1.3430954 , -0.2377062 ,\n",
       "        0.9278185 , -0.11415969, -0.4545297 ,  0.37586495, -0.14629735,\n",
       "        1.1643667 ,  0.5642611 ,  0.79735637,  0.51034147,  2.0151942 ,\n",
       "       -0.2675093 , -1.0493823 ,  0.40723312,  0.08401095, -0.52674526,\n",
       "        0.6995869 , -0.2588918 ,  0.25624406, -0.8719027 , -0.08911832,\n",
       "        0.776215  ,  0.33288407,  0.34623566, -0.16564311,  0.01750955,\n",
       "       -0.07142716, -0.64413697, -1.8633269 ,  1.3605239 , -1.0066785 ,\n",
       "        0.5455204 , -0.01215056,  0.14796275,  0.5336817 ,  1.4059262 ,\n",
       "       -0.89917177, -1.8282423 ,  0.11325808, -0.7052246 ,  0.22107765,\n",
       "        1.2132165 ,  0.3022798 ,  0.870041  ,  1.016764  , -0.5030119 ,\n",
       "       -0.7959648 ,  0.02712202, -1.119066  ,  1.3294834 , -0.5570173 ,\n",
       "       -0.06093549, -0.577442  , -0.5651625 ,  0.3288834 ,  0.3863012 ,\n",
       "       -0.2332233 , -0.7029712 ,  0.2134215 , -1.6153781 ,  0.64032334,\n",
       "        0.18149072,  0.7775019 , -0.24040484,  0.01531528, -1.3189698 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model['man'] # model.wv['man']와 같은 결과 bc, model.wv == load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://projector.tensorflow.org/\n",
    "\n",
    "- embedding vector(tensor) 파일 (.tsv)\n",
    "- metadat 파일 (.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 16:14:33,846 - word2vec2tensor - INFO - running c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input ted_en_w2v --output ted_en_w2v\n",
      "2025-04-07 16:14:33,847 - keyedvectors - INFO - loading projection weights from ted_en_w2v\n",
      "2025-04-07 16:14:34,901 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (21462, 100) matrix of type float32 from ted_en_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-04-07T16:14:34.731288', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-04-07 16:14:35,687 - word2vec2tensor - INFO - 2D tensor file saved to ted_en_w2v_tensor.tsv\n",
      "2025-04-07 16:14:35,687 - word2vec2tensor - INFO - Tensor metadata file saved to ted_en_w2v_metadata.tsv\n",
      "2025-04-07 16:14:35,688 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "# !python -m gensim.scripts.word2vec2tensor --input ted_en_w2v --output ted_en_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 한국어 Word Embedding\n",
    "- NSMC (Naver Sentiment Movie Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('naver_movie_ratings.txt', <http.client.HTTPMessage at 0x212902f72f0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\n",
    "    'https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt',\n",
    "    filename='naver_movie_ratings.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 생성\n",
    "ratings_df = pd.read_csv('naver_movie_ratings.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    8\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결측치 확인 및 처리 (제거)\n",
    "display(ratings_df.isnull().sum())\n",
    "\n",
    "ratings_df = ratings_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    많은 생각을 할 수 있는 영화~ 시간여행류의 스토리를 좋아하는 사람이라면 빠트릴 수...\n",
       "201    고소한 19 정말 재미있게 잘 보고 있습니다^^ 방송만 보면 털털하고 인간적이신 것...\n",
       "202                                                  가연세\n",
       "203                         goodgoodgoodgoodgoodgoodgood\n",
       "204                                           이물감. 시 같았다\n",
       "                             ...                        \n",
       "295                                   박력넘치는 스턴트 액션 평작이다!\n",
       "296                                      엄청 재미있다 명작이다 ~~\n",
       "297    나는 하정우랑 개그코드가 맞나보다 엄청 재밌게봤네요 특히 단발의사샘 장면에서 계속 ...\n",
       "298                                                적당 ㅎㅎ\n",
       "299                                    배경이 이쁘고 캐릭터도 귀엽네~\n",
       "Name: document, Length: 100, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['document'][200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글이 아닌 데이터 제거\n",
    "ratings_df['document'] = ratings_df['document'].replace(r'[^0-9가-힣ㄱ-ㅎㅏ-ㅣ\\s]', '', regex=True)     # 정규식에 포함되지 않는 문자를 공백으로 replace # 숫자와 한글 전체를 포함   # \\s: 공백 # regex=True: 정규표현식 패턴으로 찾을 수 있게 작성해줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    많은 생각을 할 수 있는 영화 시간여행류의 스토리를 좋아하는 사람이라면 빠트릴 수 ...\n",
       "201    고소한 19 정말 재미있게 잘 보고 있습니다 방송만 보면 털털하고 인간적이신 것 같...\n",
       "202                                                  가연세\n",
       "203                                                     \n",
       "204                                            이물감 시 같았다\n",
       "                             ...                        \n",
       "295                                    박력넘치는 스턴트 액션 평작이다\n",
       "296                                        엄청 재미있다 명작이다 \n",
       "297    나는 하정우랑 개그코드가 맞나보다 엄청 재밌게봤네요 특히 단발의사샘 장면에서 계속 ...\n",
       "298                                                적당 ㅎㅎ\n",
       "299                                     배경이 이쁘고 캐릭터도 귀엽네\n",
       "Name: document, Length: 100, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['document'][200:300] # 정규식에 포함되지 않는 문자를 사라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199992/199992 [10:03<00:00, 331.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "from tqdm import tqdm       # 진행도 시각화\n",
    "\n",
    "okt = Okt()\n",
    "ko_stopwords = ['은', '는', '이', '가', '을', '를', '와', '과', '들', '도', '부터', '까지', '에', '나', '너', '그', '걔', '얘']\n",
    "\n",
    "preprocessed_data = []\n",
    "\n",
    "for sentence in tqdm(ratings_df['document']):\n",
    "    tokens = okt.morphs(sentence, stem=True)\n",
    "    tokens = [token for token in tokens if token not in ko_stopwords]       # 불용어 제거\n",
    "    preprocessed_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16841, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = Word2Vec(\n",
    "    sentences=preprocessed_data,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0        # CBOW\n",
    ")\n",
    "\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영화관', 0.9293283820152283),\n",
       " ('틀어주다', 0.8164802193641663),\n",
       " ('케이블', 0.7858408689498901),\n",
       " ('학교', 0.7767468690872192),\n",
       " ('티비', 0.7370700836181641),\n",
       " ('인터넷', 0.7028782367706299),\n",
       " ('방금', 0.6961246728897095),\n",
       " ('영화제', 0.6846520304679871),\n",
       " ('독립영화관', 0.6845982670783997),\n",
       " ('개봉관', 0.683452844619751)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('극장')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60467035"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('아이유','토르')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.wv.save_word2vec_format('naver_movie_ratings_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:11:01,524 - word2vec2tensor - INFO - running c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input naver_movie_ratings_w2v --output naver_movie_ratings_w2v\n",
      "2025-04-07 17:11:01,524 - keyedvectors - INFO - loading projection weights from naver_movie_ratings_w2v\n",
      "2025-04-07 17:11:02,390 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (16841, 100) matrix of type float32 from naver_movie_ratings_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-04-07T17:11:02.256799', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-04-07 17:11:03,039 - word2vec2tensor - INFO - 2D tensor file saved to naver_movie_ratings_w2v_tensor.tsv\n",
      "2025-04-07 17:11:03,039 - word2vec2tensor - INFO - Tensor metadata file saved to naver_movie_ratings_w2v_metadata.tsv\n",
      "2025-04-07 17:11:03,040 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.word2vec2tensor --input naver_movie_ratings_w2v --output naver_movie_ratings_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 훈련된 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1aL_xpWW-CjfCrLWeflIaipITOZ6zHI5c\n",
      "From (redirected): https://drive.google.com/uc?id=1aL_xpWW-CjfCrLWeflIaipITOZ6zHI5c&confirm=t&uuid=8b49cc80-d2c6-47b7-a04a-ff9b545f0aad\n",
      "To: c:\\encore_skn11\\07_nlp\\03_word_embedding\\GoogleNews_vecs.bins.gz\n",
      "100%|██████████| 1.65G/1.65G [06:46<00:00, 4.05MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GoogleNews_vecs.bins.gz'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/uc?id=1aL_xpWW-CjfCrLWeflIaipITOZ6zHI5c'\n",
    "output = 'GoogleNews_vecs.bins.gz'\n",
    "\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv = KeyedVectors.load_word2vec_format('GoogleNews_vecs.bins.gz', binary=True)\n",
    "google_news_wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22942671"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similarity('king','man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.4295138120651245),\n",
       " ('queen', 0.39028695225715637),\n",
       " ('Pansy_Ho_Chiu', 0.3827225863933563),\n",
       " ('monarch', 0.3633837103843689),\n",
       " ('kingdom', 0.36145076155662537)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_new.most_similar('king','man', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510957479476929),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474),\n",
       " ('sultan', 0.5864824056625366),\n",
       " ('ruler', 0.5797566771507263),\n",
       " ('princes', 0.5646551847457886),\n",
       " ('Prince_Paras', 0.5432944297790527),\n",
       " ('throne', 0.5422105193138123)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24791393"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.n_similarity(['king','queen'], ['man','woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510957479476929),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similar_by_word('king', topn=5)      # most_similar와 같은 동작을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.has_index_for('ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

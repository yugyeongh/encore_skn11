{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts-nLR_PIpiw"
      },
      "source": [
        "# 멜로디 생성하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2L9p80HImV_",
        "outputId": "93d3570a-ea30-4816-b57f-44d2da6c8a5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "Config of the audio_encoder: <class 'transformers.models.encodec.modeling_encodec.EncodecModel'> is overwritten by shared audio_encoder config: EncodecConfig {\n",
            "  \"architectures\": [\n",
            "    \"EncodecModel\"\n",
            "  ],\n",
            "  \"audio_channels\": 1,\n",
            "  \"chunk_length_s\": null,\n",
            "  \"codebook_dim\": 128,\n",
            "  \"codebook_size\": 2048,\n",
            "  \"compress\": 2,\n",
            "  \"dilation_growth_rate\": 2,\n",
            "  \"hidden_size\": 128,\n",
            "  \"kernel_size\": 7,\n",
            "  \"last_kernel_size\": 7,\n",
            "  \"model_type\": \"encodec\",\n",
            "  \"norm_type\": \"weight_norm\",\n",
            "  \"normalize\": false,\n",
            "  \"num_filters\": 64,\n",
            "  \"num_lstm_layers\": 2,\n",
            "  \"num_residual_layers\": 1,\n",
            "  \"overlap\": null,\n",
            "  \"pad_mode\": \"reflect\",\n",
            "  \"residual_kernel_size\": 3,\n",
            "  \"sampling_rate\": 32000,\n",
            "  \"target_bandwidths\": [\n",
            "    2.2\n",
            "  ],\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.1\",\n",
            "  \"trim_right_ratio\": 1.0,\n",
            "  \"upsampling_ratios\": [\n",
            "    8,\n",
            "    5,\n",
            "    4,\n",
            "    4\n",
            "  ],\n",
            "  \"use_causal_conv\": false,\n",
            "  \"use_conv_shortcut\": false\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.musicgen.modeling_musicgen.MusicgenForCausalLM'> is overwritten by shared decoder config: MusicgenDecoderConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"audio_channels\": 1,\n",
            "  \"bos_token_id\": 2048,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"ffn_dim\": 4096,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_factor\": 0.02,\n",
            "  \"layerdrop\": 0.0,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"musicgen_decoder\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codebooks\": 4,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 2048,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 2048\n",
            "}\n",
            "\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import scipy\n",
        "\n",
        "synthesiser = pipeline('text-to-audio', 'facebook/musicgen-small')\n",
        "\n",
        "music = synthesiser('jazz festival in forest', forward_params={'do_sample': True})\n",
        "\n",
        "scipy.io.wavfile.write('musicgen_output.wav',\n",
        "                       rate=music['sampling_rate'],\n",
        "                       data=music['audio'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQ9qY7_QNPHT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Using cached gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
            "Using cached gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "tts = gTTS(text='안녕하세요, 저는 래빗입니다. 좋은 하루입니다!', lang='ko')\n",
        "\n",
        "tts.save('gtts_output.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (0.25.1)\n",
            "Requirement already satisfied: pyaudio in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (0.2.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (3.14.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "말씀하세요.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:     \u001b[38;5;66;03m# 마이크로부터 음성 감지\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m말씀하세요.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# 음성 데이터 수집\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         txt \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m'\u001b[39m)      \u001b[38;5;66;03m# 음성을 텍스트로 변환\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 음성 입력 -> 텍스트 출력\n",
        "\n",
        "import speech_recognition as sr\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "while True: # 마이크로부터 음성을 계속 입력받기 위한 무한 루프\n",
        "    with sr.Microphone() as source:     # 마이크로부터 음성 감지\n",
        "        print('말씀하세요.')\n",
        "        audio = recognizer.listen(source)   # 음성 데이터 수집\n",
        "        try:\n",
        "            txt = recognizer.recognize_google(audio, language='ko-KR')      # 음성을 텍스트로 변환\n",
        "            print(txt)\n",
        "            \n",
        "            if '끝' in txt: \n",
        "                print(\"프로그램을 종료합니다.\")\n",
        "                break \n",
        "        except sr.UnknownValueError:\n",
        "            print(\"음성을 이해할 수 없습니다.\")\n",
        "        except sr.RequestError:\n",
        "            print(\"Google Speech Recognition 서비스에 요청할 수 없습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요 저는\n"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "# .mp3 -> .wav 변환\n",
        "# ffmpeg를 설치하지 않으면 사용할 수 없음\n",
        "audio = AudioSegment.from_mp3('gtts_output.mp3')\n",
        "audio.export('gtts_output_wav.wav', format='wav')\n",
        "\n",
        "# 파일 로드\n",
        "r = sr.Recognizer()\n",
        "input_audio = sr.AudioFile('gtts_output_wav.wav')\n",
        "\n",
        "# 음성 데이터 -> 텍스트 변환\n",
        "with input_audio as source:\n",
        "    audio = r.record(source)        # 파일에 있는 내용을 데이터 자체로 변환\n",
        "\n",
        "result_txt = r.recognize_google(audio_data=audio, language='ko-KR')\n",
        "print(result_txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pystudy_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 (Ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting\n",
    "- hard voting: 여러 개의 예측치에 대해 다수결로 결정\n",
    "- soft voting: 여러 개의 예측 확률을 평균내어 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위스콘신 유방암 데이터셋 (Wisconsin Breast Cancer Dataset)\n",
    "\n",
    "유방암의 악성(Malignant)과 양성(Benign)을 분류하기 위해 자주 사용되는 데이터셋\n",
    "(의학적인 이미지를 바탕으로 유방암 종양의 특징을 수치화한 데이터)\n",
    "\n",
    "**데이터셋 개요**\n",
    "- **목적**: 유방암 종양이 악성(Malignant)인지, 양성(Benign)인지 분류\n",
    "- **샘플 수**: 569개\n",
    "- **특징(Features) 수**: 30개 (==30개의 컬럼)\n",
    "- **타겟(Target)**: 0(악성) 또는 1(양성)\n",
    "\n",
    "**데이터 구성**\n",
    "1. **Radius mean**: 종양의 평균 반지름\n",
    "2. **Texture mean**: 종양의 표면의 거칠기\n",
    "3. **Perimeter mean**: 종양의 평균 둘레 길이\n",
    "4. **Area mean**: 종양의 평균 면적\n",
    "5. **Smoothness mean**: 종양의 매끄러움 정도\n",
    "6. **Compactness mean**: 종양의 압축도\n",
    "7. **Concavity mean**: 종양의 오목함\n",
    "8. **Concave points mean**: 종양의 오목한 점 개수\n",
    "9. **Symmetry mean**: 종양의 대칭성\n",
    "10. **Fractal dimension mean**: 종양의 프랙탈 차원 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "# data.keys() #['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n",
    "# print(data.DESCR)\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30), (426,), (143,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  데이터 준비 (분리)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 점수:  0.9647887323943662\n",
      "테스트 점수:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 객체 생성\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn_clf', knn_clf),\n",
    "        ('lr_clf', lr_clf),\n",
    "        ('dt_clf', dt_clf)\n",
    "    ], # 투표에 참여할 모델들\n",
    "    voting='hard' # default 값\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_train = voting_clf.predict(X_train)\n",
    "acc_score_train = accuracy_score(y_train, y_pred_train) # 실제값과 예측값 넣어 평가\n",
    "print('학습 점수: ', acc_score_train)\n",
    "\n",
    "y_pred_test = voting_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test) # 실제값과 예측값 넣어 평가\n",
    "print('테스트 점수: ', acc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 예측값:  [0 1 0 1 0 0 1 1 1 0]\n",
      "---------------\n",
      "KNeighborsClassifier 개별 정확도:  0.9371\n",
      "KNeighborsClassifier 예측값: [0 1 0 1 0 0 1 1 1 0]\n",
      "---------------\n",
      "LogisticRegression 개별 정확도:  0.9441\n",
      "LogisticRegression 예측값: [0 1 0 1 0 0 1 1 1 0]\n",
      "---------------\n",
      "DecisionTreeClassifier 개별 정확도:  0.8671\n",
      "DecisionTreeClassifier 예측값: [0 1 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# hard voting 작동 원리 == 다수결\n",
    "start, end = 40, 50\n",
    "voting_clf_pred = voting_clf.predict(X_test[start:end])\n",
    "print('앙상블 예측값: ', voting_clf_pred)\n",
    "\n",
    "for classifier in [knn_clf, lr_clf, dt_clf]:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, pred)\n",
    "\n",
    "    class_name = classifier.__class__.__name__ # 객체를 중심으로 해서 클래스의 이름 속성을\n",
    "    print('---------------')\n",
    "    print(f'{class_name} 개별 정확도: {acc_score: .4f}')\n",
    "    print(f'{class_name} 예측값: {pred[start:end]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 점수:  0.9859154929577465\n",
      "테스트 점수:  0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 객체 생성\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier(random_state=0) # 설정 안하면 test 점수 바뀜뀜\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn_clf', knn_clf),\n",
    "        ('lr_clf', lr_clf),\n",
    "        ('dt_clf', dt_clf)\n",
    "    ], # 투표에 참여할 모델들\n",
    "    voting='soft' # default 값\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_train = voting_clf.predict(X_train)\n",
    "acc_score_train = accuracy_score(y_train, y_pred_train) # 실제값과 예측값 넣어 평가\n",
    "print('학습 점수: ', acc_score_train)\n",
    "\n",
    "y_pred_test = voting_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test) # 실제값과 예측값 넣어 평가\n",
    "print('테스트 점수: ', acc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 예측값:  [[5.70263157e-01 4.29736843e-01]\n",
      " [1.08113730e-03 9.98918863e-01]\n",
      " [9.99622506e-01 3.77494355e-04]\n",
      " [3.35757426e-04 9.99664243e-01]\n",
      " [9.00993416e-01 9.90065841e-02]\n",
      " [1.00000000e+00 1.75163138e-13]\n",
      " [7.79971341e-05 9.99922003e-01]\n",
      " [1.83004552e-02 9.81699545e-01]\n",
      " [1.14568790e-03 9.98854312e-01]\n",
      " [9.32982089e-01 6.70179112e-02]]\n",
      "각 모델별 예측값의 평균: [[5.70263157e-01 4.29736843e-01]\n",
      " [1.08113730e-03 9.98918863e-01]\n",
      " [9.99622506e-01 3.77494355e-04]\n",
      " [3.35757426e-04 9.99664243e-01]\n",
      " [9.00993416e-01 9.90065841e-02]\n",
      " [1.00000000e+00 1.75163138e-13]\n",
      " [7.79971341e-05 9.99922003e-01]\n",
      " [1.83004552e-02 9.81699545e-01]\n",
      " [1.14568790e-03 9.98854312e-01]\n",
      " [9.32982089e-01 6.70179112e-02]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# soft voting 작동 원리 == 각 예측기의 확률값 평균\n",
    "# 모델이 계산한 값과 직접 평균 계산한 값이 같은지 확인하기\n",
    "start, end = 40, 50\n",
    "\n",
    "voting_clf_pred_proba = voting_clf.predict_proba(X_test[start:end])\n",
    "print('앙상블 예측값: ', voting_clf_pred_proba)\n",
    "\n",
    "averages = np.full_like(voting_clf_pred_proba, 0)\n",
    "\n",
    "for classifier in [knn_clf, lr_clf, dt_clf]:\n",
    "    # 개별 학습 및 예측\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, pred)\n",
    "    pred_proba = classifier.predict_proba(X_test[start:end])\n",
    "\n",
    "    # 예측 확률 평균을 위한 합계\n",
    "    averages += pred_proba\n",
    "\n",
    "    class_name = classifier.__class__.__name__ # 객체를 중심으로 해서 클래스의 이름 속성을\n",
    "    # print('---------------')\n",
    "    # print(f'{class_name} 개별 정확도: {acc_score: .4f}')\n",
    "    # print(f'{class_name} 예측 확률: {pred_proba}')\n",
    "\n",
    "# 예측 확률 평균 계산 및 출력\n",
    "calc_averages = averages / 3\n",
    "print('각 모델별 예측값의 평균:', calc_averages)\n",
    "print(np.array_equal(voting_clf_pred_proba, calc_averages)) # True -> 각 데이터가 같은 위치에 같은 값을 가지고 있는지 확인해주는 함수:array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "- Bootstrap Aggregation\n",
    "- Bootstrap 방식의 샘플링: 각 estimator마다 훈련 데이터를 뽑을 때, 중복값을 허용하는 방식\n",
    "- 분류 모델의 경우, 각 tree(estimator)의 예측값을 다수결(hard voting) 결정\n",
    "- 회귀 모델의 경우, 각 tree(estimator)의 예측값을 평균내어 결정\n",
    "- 기본적으로 100개의 tree 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이퍼 파라미터**\n",
    "| **하이퍼파라미터**      | **설명**                                                                                     | **기본값**      |\n",
    "|--------------------------|--------------------------------------------------------------------------------------------|-----------------|\n",
    "| `n_estimators`           | 생성할 트리의 개수 지정 (트리의 개수가 많을수록 성능이 좋아질 수 있지만 계산 비용 증가) | 100             |\n",
    "| `criterion`              | 분할 품질을 측정하는 기준 (분류에서는 \"gini\" 또는 \"entropy\"를 사용)                 | \"gini\"          |\n",
    "| `max_depth`              | 각 트리의 최대 깊이 (설정하지 않으면 트리는 잎 노드가 순수해질 때까지 계속 확장) | None            |\n",
    "| `min_samples_split`      | 내부 노드를 분할하기 위해 필요한 최소 샘플 수 (과적합 방지 목적)                   | 2               |\n",
    "| `min_samples_leaf`       | 잎 노드가 되기 위해 필요한 최소 샘플 수 (과적합 방지 목적)                          | 1               |\n",
    "| `max_features`           | 각 트리를 분할할 때 고려할 최대 특성 수 ()\"auto\", \"sqrt\", \"log2\" 중 선택하거나, 특정 숫자 지정 가능) | \"auto\"          |\n",
    "| `bootstrap`              | 각 트리를 만들 때 부트스트랩 샘플링을 사용할지 여부를 결정                               | True            |\n",
    "| `random_state`           | 결과의 재현성을 위해 난수 시드 고정                                                  | None            |\n",
    "| `n_jobs`                 | 병렬 계산을 위해 사용할 CPU 코어 수를 지정 (-1로 설정하면 모든 코어를 사용)           | None            |\n",
    "| `class_weight`           | 각 클래스의 가중치를 자동으로 계산하거나 직접 지정 가능 (불균형 데이터 처리에 유용)    | None            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 점수:  0.9859154929577465\n",
      "테스트 평가 점수:  0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=7, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 학습\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = rf_clf.predict(X_train)\n",
    "acc_scrore_train = accuracy_score(y_train, y_pred_train)\n",
    "print('학습 점수: ', acc_score_train)\n",
    "\n",
    "y_pred_test = rf_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test)\n",
    "print('테스트 평가 점수: ', acc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# 100개의 decisiontree 확인\n",
    "# print(rf_clf.estimators_)\n",
    "\n",
    "# 100개의 decisiontree가 사용한 샘플 데이터 확인\n",
    "print(len(rf_clf.estimators_samples_)) # 예측기가 100개라 100개로 확인됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
